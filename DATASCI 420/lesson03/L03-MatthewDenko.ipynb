{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 03 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "    A superstore wants to identify customer groupings that visit their stores based on customer transaction (sales) data. These groupings are used for targeted promotions. You are asked to perform customer segmentation on the provided data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "    Using the Superstore Transaction dataset, create a new notebook and perform each of the following tasks and answer the related questions:\n",
    "\n",
    "    (1) Read dataset\n",
    "    (2) Calculate the Recency, Frequency, Monitory for each customer\n",
    "    (3) Using K-means algorithm, perform customer segmentation\n",
    "    (4) Describe your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Plot styling\n",
    "\n",
    "import seaborn as sns; sns.set()  # for plot styling\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading url\n",
    "\n",
    "data = pd.read_csv(\"/Users/matt.denko/Downloads/SuperstoreTransaction.csv\") \n",
    "data.columns = [\"Row ID\",\n",
    "\"Order ID\",\n",
    "\"Order Date\",\n",
    "\"Ship Date\",\n",
    "\"Ship Mode\",\n",
    "\"Customer ID\",\n",
    "\"Customer Name\",\n",
    "\"Segment\",\n",
    "\"Country\",\n",
    "\"City\",\n",
    "\"State\",\n",
    "\"Postal Code\",\n",
    "\"Region\",\n",
    "\"Product ID\",\n",
    "\"Category\",\n",
    "\"Sub-Category\",\n",
    "\"Product Name\",\n",
    "\"Sales\",\n",
    "\"Quantity\",\n",
    "\"Discount\",\n",
    "\"Profit\"]\n",
    "print(data.columns)\n",
    "data.describe()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing cases with missing data\n",
    "\n",
    "data = data.replace(to_replace= \"?\", value=float(\"NaN\"))\n",
    "data_null = data.isnull().sum()\n",
    "print(data_null)\n",
    "print(\"There are 0 columns with missing data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Calculate the Recency, Frequency, Monitory for each customer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Timestamp to Datetime Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order Date\n",
    "\n",
    "data[\"Order Date\"] = pd.to_datetime(data[\"Order Date\"], format='%m/%d/%Y')\n",
    "data.head()\n",
    "print(\"Minimal Order Date=%s, Maximal Order Date=%s\"%(min(data[\"Order Date\"]).strftime(\"%Y-%m-%d %H:%M\"), \\\n",
    "                                          max(data[\"Order Date\"]).strftime(\"%Y-%m-%d %H:%M\")))\n",
    "\n",
    "# Ship Date\n",
    "\n",
    "data[\"Ship Date\"] = pd.to_datetime(data[\"Ship Date\"], format='%m/%d/%Y')\n",
    "data.head()\n",
    "print(\"Minimal Ship Date=%s, Maximal Ship Date=%s\"%(min(data[\"Ship Date\"]).strftime(\"%Y-%m-%d %H:%M\"), \\\n",
    "                                          max(data[\"Ship Date\"]).strftime(\"%Y-%m-%d %H:%M\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recency, Frequency, Monitory Calculation\n",
    "\n",
    "Start_Date_Obj = dt.datetime.strptime(\"1/1/2014\", \"%m/%d/%Y\")\n",
    "End_Date_Obj = dt.datetime.strptime(\"1/10/2018\", \"%m/%d/%Y\")\n",
    "Time_Window = 60 #days. Only consider customers who have activities within the recent 60 days\n",
    "FM_Window = 7 #days for frequency and monetary\n",
    "\n",
    "check_point_date = Start_Date_Obj\n",
    "UserID = []\n",
    "Checkpoint = []\n",
    "Recency = []\n",
    "Frequency = []\n",
    "Monetary_Value = []\n",
    "Monetary_Quantity = []\n",
    "while check_point_date <= End_Date_Obj:\n",
    "    window_start = check_point_date - dt.timedelta(days = Time_Window)\n",
    "    mask = (data[\"Order Date\"] >= window_start) & (data[\"Order Date\"] < check_point_date)\n",
    "    # Get the data in [checkpoint-60days, checkpoint]\n",
    "    data_checkpoint = data.loc[mask]\n",
    "    # Get the ids of users who have activities in [checkpoint-60days, checkpoint]\n",
    "    unique_users = list(set(data_checkpoint[\"Customer ID\"]))\n",
    "    print(\"There are %d unique users.\"%(len(unique_users)))\n",
    "    FM_Window_Start = check_point_date - dt.timedelta(days = FM_Window)\n",
    "    for user in unique_users:\n",
    "        UserID.append(user)\n",
    "        Checkpoint.append(check_point_date)\n",
    "        mask = data_checkpoint[\"Customer ID\"] == user\n",
    "        data_checkpoint_user = data_checkpoint.loc[mask]\n",
    "        delta = check_point_date - max(data_checkpoint_user[\"Order Date\"])\n",
    "        recency = delta.days #Recency, days between checkpoint and last transaction time\n",
    "        mask = data_checkpoint_user[\"Order Date\"] >= FM_Window_Start\n",
    "        data_checkpoint_user_fm = data_checkpoint_user.loc[mask]\n",
    "        frequency = data_checkpoint_user_fm.shape[0]\n",
    "        value = np.sum(data_checkpoint_user_fm.iloc[:, 8]) #monetary values\n",
    "        quantity = np.sum(data_checkpoint_user_fm.iloc[:, 7])#monetary quantity\n",
    "        Recency.append(recency)\n",
    "        Frequency.append(frequency)\n",
    "        Monetary_Value.append(value)\n",
    "        Monetary_Quantity.append(quantity)\n",
    "    check_point_date = check_point_date + dt.timedelta(days = 1)\n",
    "# Consolidate all columns into a signle data frame\n",
    "RFM_Dict = OrderedDict([ ('Customer ID', UserID),\n",
    "          ('Checkpoint', Checkpoint),\n",
    "          ('Recency',  Recency),\n",
    "          ('Frequency', Frequency),\n",
    "          ('Value', Monetary_Value),\n",
    "          ('Quantity', Monetary_Quantity)] )\n",
    "RFM_Frame = pd.DataFrame.from_dict(RFM_Dict)\n",
    "RFM_Frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Using K-means algorithm, perform customer segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting Data for columns to use for k-means\n",
    "\n",
    "X = pd.DataFrame()\n",
    "X.loc[:,\"Sales\"] = data.loc[:,\"Sales\"]\n",
    "X.loc[:,\"Profit\"] = data.loc[:,\"Profit\"]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the elbow method to find the optimum number of clusters\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "wcss = []\n",
    "for i in range(1,10):\n",
    "    km=KMeans(n_clusters=i,init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    km.fit(X)\n",
    "    wcss.append(km.inertia_)\n",
    "plt.plot(range(1,10),wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('wcss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting kmeans to the dataset with k=3\n",
    "\n",
    "X = np.array(X)\n",
    "km4=KMeans(n_clusters=3,init='k-means++', max_iter=10, n_init=10, random_state=0)\n",
    "y_means = km4.fit_predict(X)\n",
    "print(y_means)\n",
    "\n",
    "# Visualizing the clusters for k=3\n",
    "\n",
    "plt.scatter(X[y_means==0,0],X[y_means==0,1],s=50, c='purple',label='Cluster1')\n",
    "plt.scatter(X[y_means==1,0],X[y_means==1,1],s=50, c='blue',label='Cluster2')\n",
    "plt.scatter(X[y_means==2,0],X[y_means==2,1],s=50, c='green',label='Cluster3')\n",
    "plt.scatter(km4.cluster_centers_[:,0], km4.cluster_centers_[:,1],s=200,marker='s', c='red', alpha=0.7, label='Centroids')\n",
    "plt.title('Customer segments')\n",
    "plt.xlabel('Annual sales of customer')\n",
    "plt.ylabel('Annual profit from customer')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Describe your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments:\n",
    "\n",
    "    In the Recency, Frequency, Monetary calculation the slices with the highest Recency and Frequency scores were two customer ids in United States - Consumer.\n",
    "    \n",
    "    In the k-means customer segmentation based off the elbow graph I chose 3 clusters. Cluster 1 and 2 appear to have some overlap while cluster 3 is very spread out."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
