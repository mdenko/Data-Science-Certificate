{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 05 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "    Rooney's client is a tech-manufacturing startup working on a number of automated detection devices for the medical and construction industries. Among the auto-detection devices is a reader that looks at possible carcinoma tissue samples to classify the sample as either benign or malignant. Rooney asks you for help in developing a better algorithm than the current classifier, perhaps a decision tree can help.\n",
    "\n",
    "    For this assignment, you will be designing an experiment using decision tree classifiers for the detection of breast cancer and comparing the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Details\n",
    "\n",
    "    The Breast Cancer Wisconsin Data Set (Links to an external site.)Links to an external site. data were obtained from the University of Wisconsin Hospitals, Madison. Donors:\n",
    "\n",
    "    (1) Dr. William H. Wolberg, General Surgery Dept.\n",
    "    (2) W. Nick Street, Computer Sciences Dept.\n",
    "    (3) Olvi L. Mangasarian, Computer Sciences Dept.\n",
    "    (4) They contain the simplified and normalized attributes used to detect breast cancer. \n",
    "\n",
    "    Attributes:\n",
    "    (1) Sample code number: id number\n",
    "    (2) Class (4 for malignant, 2 for benign)\n",
    "    (3) Clump Thickness: 1 - 10\n",
    "    (4) Uniformity of Cell Size: 1 - 10\n",
    "    (5) Uniformity of Cell Shape: 1 - 10\n",
    "    (6) Marginal Adhesion: 1 - 10\n",
    "    (7) Single Epithelial Cell Size: 1 - 10\n",
    "    (8) Bare Nuclei: 1 - 10\n",
    "    (9) Bland Chromatin: 1 - 10\n",
    "    (10) Normal Nucleoli: 1 - 10\n",
    "    (11) Mitosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "    It is recommended you complete the lab exercises for this lesson before beginning the assignment.\n",
    "\n",
    "    Using the WI_Breast_Cancer csv file, create a new notebook to build a decision tree classifier that would be able to detect whether a tumor is benign or malignant. Complete the following tasks and answer the questions:\n",
    "\n",
    "    -Read Data\n",
    "    -Test both entropy and the gini coefficient. Which performs better and why?\n",
    "    -What are the best hyperparameter settings for both?\n",
    "    -Determine the AUC for the best model you can achieve. What are the precision and recal values and which might be the one you want to maximize?\n",
    "    -What are the implications of using this type of machine learning algorithm for breast cancer analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "#Plot styling\n",
    "\n",
    "import seaborn as sns; sns.set()  # for plot styling\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading url\n",
    "\n",
    "data = pd.read_csv(\"/Users/matt.denko/Downloads/WI_Breast_Cancer.csv\") \n",
    "data.columns = ['sample_id','class','clump_thickness', 'cell_size', 'cell_shape','adhesion',\n",
    "                'epithelial','nuclei','chromatin','nucleoli','mitosis'] \n",
    "(nrows, ncols) = data.shape\n",
    "print(data.columns)\n",
    "data.describe()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing cases with missing data\n",
    "\n",
    "data = data.replace(to_replace= \"?\", value=float(\"NaN\"))\n",
    "data_null = data.isnull().sum()\n",
    "print(data_null)\n",
    "print(\"There are 0 columns with missing data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test both entropy and the gini coefficient. Which performs better and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert string features to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string features to integers\n",
    "\n",
    "colnames = list(data.columns.values)\n",
    "string_encoding = {}\n",
    "data_encoded = data.copy()\n",
    "for i in range(ncols):\n",
    "    levels = list(set(data.iloc[:, i]))\n",
    "    num_levels = len(levels)\n",
    "    string_encoding_i = dict(zip(levels, range(num_levels)))\n",
    "    string_encoding[colnames[i]] = string_encoding_i\n",
    "    for j in range(nrows):\n",
    "        data_encoded.iloc[j, i] = string_encoding_i[data.iloc[j, i]]\n",
    "\n",
    "print(string_encoding)\n",
    "print(data_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding Categorial Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoding Categorical Variables\n",
    "\n",
    "target_label = 'class'\n",
    "feature_labels = [x for x in data_encoded.columns if x not in [target_label]]\n",
    "x = data_encoded[feature_labels]\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(x.iloc[:,0:4])\n",
    "data_onehotencoded = enc.transform(x.iloc[:,0:4])\n",
    "feature_names = ['sample_id','class','clump_thickness', 'cell_size', 'cell_shape','adhesion',\n",
    "                'epithelial','nuclei','chromatin','nucleoli','mitosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign the X (feature) and Y (class) Arrays and Split into Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and Test Data\n",
    "# Ensure the decision tree is deterministic\n",
    "\n",
    "np.random.seed(101)\n",
    "\n",
    "X = data_onehotencoded.toarray()\n",
    "Y = data_encoded[target_label]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state = 99)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and Evaluate the Model - Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Classification model\n",
    "\n",
    "dec_tree_ent = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "model = dec_tree_ent.fit(X_train,y_train)\n",
    "\n",
    "# Validate the model\n",
    "\n",
    "y_predict_ent = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the accuracy score\n",
    "#def measure_performance(X_train, y_train)\n",
    "\n",
    "acc_ent = accuracy_score(y_test, y_predict_ent) * 100\n",
    "print(\"Entropy Accuracy is : {}%\".format(acc_ent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Confusion Matrix\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_predict_ent),\n",
    "    columns=['Predicted Benign', 'Predicted Malignant'],\n",
    "    index=['True Benign', 'True Malignant']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Gini impurity (default) instead of Information Gain (entropy)\n",
    "\n",
    "dec_tree_gini = DecisionTreeClassifier().fit(X_train,y_train)  \n",
    "\n",
    "# Validate the model\n",
    "\n",
    "y_predict_gini = dec_tree_gini.predict(X_test)\n",
    "\n",
    "# Generate the accuracy score\n",
    "\n",
    "acc_gini = accuracy_score(y_test, y_predict_gini) * 100\n",
    "print(\"Gini Accuracy is : {}%\".format(acc_gini))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments:\n",
    "\n",
    "    The accuracy of the entropy model was 94% while the accuracy of the gini model was 97%\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the best hyperparameter settings for both?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments: \n",
    "\n",
    "    Both the gini and entropy have extremley high accuracy scores. Both of the accuracy scores are above 90% so we can conclude that having all features and replacing null values with 0s provides the best hyperparameter tuning for both the gini and the entropy model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the AUC for the best model you can achieve. What are the precision and recal values and which might be the one you want to maximize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_predict_gini)\n",
    "print(\"AUC score: \",auc_score)\n",
    "\n",
    "#Precision-Recall\n",
    "\n",
    "prfs = precision_recall_fscore_support(y_test, y_predict_gini, average='macro')\n",
    "print(\"Precision, Recall, Fscore: \", prfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments: \n",
    "\n",
    "    The AUC score is .98, the precision score is .94, and the recall score is .98. The accuracy of this model is .94. These are all extremely high and good scores. In this case we do not need to maximize precision or recall as they are close to being maximized as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the implications of using this type of machine learning algorithm for breast cancer analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments: \n",
    "\n",
    "     Becuase this analysis is focused on a delicate medical issue such as Breast Cancer the takeaways from any study can have huge implications. In this case since we are predicting whether or not a person has breast cancer we would ideally want to reduce the amount of False Negatives. Since in that case we would be missing a diagnosis and potenatilly having a participant with Breast Cancer go untreated. But machine learning can help Breast Cancer treatment in finding easier ways to detect cancerous tumors at an earlier stage."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
