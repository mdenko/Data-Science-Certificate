{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2\n",
    "\n",
    "## Author - Matthew Denko\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "    Milestone 2 focuses on Unit 2 of the course. You will apply what you have learned about statistical analysis and hypothesis testing to the data and the problem you have selected.\n",
    "\n",
    "    For Milestone 2 you should:\n",
    "\n",
    "    (1) explore the dataset supported by charts and summary statistics;\n",
    "    (2) identify a likely distribution for several of the features;\n",
    "    (3) compute basic summary statistics by both classical, bootstrap, and Bayesian methods;\n",
    "    (4) compute confidence intervals for the above summary statistics by classical, bootstrap, and Bayesian methods; and\n",
    "    (5) leverage confidence intervals in performing hypothesis tests to determine if the differences in pairs and multiple populations are significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Explore the dataset supported by charts and summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing/Cleaning Data/Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import sem, t\n",
    "from scipy import mean\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Functions\n",
    "\n",
    "def plot_hist(x, p=5):\n",
    "    # Plot the distribution and mark the mean\n",
    "    pyplot.hist(x, alpha=.5)\n",
    "    pyplot.axvline(x.mean())\n",
    "    # 95% confidence interval    \n",
    "    pyplot.axvline(np.percentile(x, p/2.), color='red', linewidth=3)\n",
    "    pyplot.axvline(np.percentile(x, 100-p/2.), color='red', linewidth=3)\n",
    "    \n",
    "def bern_pmf(x, p):\n",
    "    if (x == 1):\n",
    "        return p\n",
    "    elif (x == 0):\n",
    "        return 1 - p\n",
    "    else:\n",
    "        return \"Value Not in Support of Distribution\"\n",
    "    \n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), st.sem(a)\n",
    "    h = se * st.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return print(\"The mean is:\",m, \"The lower bound is:\",m-h, \"The upper bound is\",m+h)\n",
    "\n",
    "def t_test(a, b, alpha, alternative='two-sided'):\n",
    "    from scipy import stats\n",
    "    import scipy.stats as ss\n",
    "    import pandas as pd\n",
    "    import statsmodels.stats.weightstats as ws\n",
    "    \n",
    "    diff = a.mean() - b.mean()\n",
    "\n",
    "    res = ss.ttest_ind(a, b)\n",
    "      \n",
    "    means = ws.CompareMeans(ws.DescrStatsW(a), ws.DescrStatsW(b))\n",
    "    confint = means.tconfint_diff(alpha=alpha, alternative=alternative, usevar='unequal') \n",
    "    degfree = means.dof_satt()\n",
    "\n",
    "    index = ['DegFreedom', 'Difference', 'Statistic', 'PValue', 'Low95CI', 'High95CI']\n",
    "    return pd.Series([degfree, diff, res[0], res[1], confint[0], confint[1]], index = index)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data\n",
    "\n",
    "url = \"https://library.startlearninglabs.uw.edu/DATASCI410/Datasets/Automobile%20price%20data%20_Raw_.csv\"\n",
    "Auto = pd.read_csv(url, header=None)\n",
    "\n",
    "#Assigning Column Names\n",
    "\n",
    "Auto.columns = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\", \"body-style\", \"drive-wheels\",\n",
    "               \"engine-location\", \"wheel-base\",\"length\", \"width\", \"height\", \"curb-weight\", \"engine-type\", \"num-of=cylinders\",\n",
    "               \"engine-size\", \"fuel-system\", \"bore\", \"stroke\", \"compression-ratio\",\"horsepower\",\"peak-rpm\",\"city-mpg\",\n",
    "               \"highway-mpg\",\"price\"]\n",
    "print(Auto.columns)\n",
    "print(Auto.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics\n",
    "\n",
    "print(Auto.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing cases with missing data\n",
    "\n",
    "Auto.loc ['price',:] = pd.to_numeric(Auto['price'], errors='coerce').fillna(0)\n",
    "Auto = Auto.replace(to_replace= \"?\", value= float('NaN'))\n",
    "\n",
    "# Dropping rows with nulls\n",
    "\n",
    "Auto = Auto.dropna(axis = 0)\n",
    "Auto_null = Auto.isnull().sum()\n",
    "print(\"\"\"Null Counts by Column\n",
    "\"\"\",Auto_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Data to numeric\n",
    "\n",
    "#price\n",
    "Auto.loc [:,'price'] = pd.to_numeric(Auto['price'], errors='coerce').fillna(0)\n",
    "Auto.loc[:,'price'] = Auto['price'].astype('float')\n",
    "\n",
    "#horsepower\n",
    "Auto.loc [:,'horsepower'] = pd.to_numeric(Auto['horsepower'], errors='coerce').fillna(0)\n",
    "Auto.loc[:,'horsepower'] = Auto['horsepower'].astype('float')\n",
    "\n",
    "#height\n",
    "Auto.loc [:,'height'] = pd.to_numeric(Auto['height'], errors='coerce').fillna(0)\n",
    "Auto.loc[:,'height'] = Auto['height'].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "    \n",
    "    All null values have now been removed from the dataset. And the feautures that I want to explore further have been converted numeric values. I will be focusing my analysis on three features: price, horsepower, and height. In the next section I will be taking a graphical look at their distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price\n",
    "\n",
    "price_hist = plot_hist(Auto.loc[:,'price'])\n",
    "plt.show(price_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "    Price appears to be slightly normal distribution with a right skew. The mean is around 12,000 however the Q3 value is near 28,000 showing the strength of the tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horsepower\n",
    "\n",
    "hp_hist = plot_hist(Auto.loc[:,'horsepower'])\n",
    "plt.show(hp_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "    Horsepower also appears to have a slightly normal distribution. It has high concentration between 50 and 125 with a mean of around 98."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# height \n",
    "\n",
    "height_hist = plot_hist(Auto.loc[:,'height'])\n",
    "plt.show(height_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "    Height is strongly left skewed as the majority of results are in between 45 and 60 with some outliers less than 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Identify a likely distribution for several of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "    For the identifying of a likely distribution for the three features I chose (price, horsepower, and height) I want to convert them each to probability values and create a new subsetted dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting Data Frame for necessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Data to numeric\n",
    "\n",
    "#price\n",
    "Auto.loc [:,'price'] = pd.to_numeric(Auto['price'], errors='coerce').fillna(0)\n",
    "Auto.loc[:,'price'] = Auto['price'].astype('float')\n",
    "\n",
    "#horsepower\n",
    "Auto.loc [:,'horsepower'] = pd.to_numeric(Auto['horsepower'], errors='coerce').fillna(0)\n",
    "Auto.loc[:,'horsepower'] = Auto['horsepower'].astype('float')\n",
    "\n",
    "#height\n",
    "Auto.loc [:,'height'] = pd.to_numeric(Auto['height'], errors='coerce').fillna(0)\n",
    "Auto.loc[:,'height'] = Auto['height'].astype('float')\n",
    "\n",
    "#Determing Mean Values\n",
    "\n",
    "#price\n",
    "price_mean = Auto['price'].mean()\n",
    "print('Price Mean is: $', price_mean)\n",
    "\n",
    "#horsepower\n",
    "hp_mean = Auto['horsepower'].mean()\n",
    "print('Horespower Mean is :', hp_mean)\n",
    "\n",
    "#height\n",
    "height_mean = Auto['height'].mean()\n",
    "print('Height Mean is:', height_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "    I will now create a new dataframe for 1 or 0 indicators of whether or not each of the columns are greater than the interger value of the mean. For price this will be 11,374. For Horsepower this will be 171. For Height this will be 54."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating New Data Frame for probabilities\n",
    "\n",
    "auto_new = pd.DataFrame()\n",
    "\n",
    "#price\n",
    "auto_new.loc[:,'price'] = (Auto.loc[:,'price'] > 11374).astype(int)\n",
    "\n",
    "#horsepower\n",
    "auto_new.loc[:,'horsepower'] = (Auto.loc[:,'horsepower'] > 171).astype(int)\n",
    "\n",
    "#height\n",
    "auto_new.loc[:,'height'] = (Auto.loc[:,'height'] > 54).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "    Each of the variables have now been converted to probability variables. So for price, horsepower, and height I choose a Bernouili distribution for parameter p, the probability that they are above their mean values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Compute basic summary statistics by both classical, bootstrap, and Bayesian methods\n",
    "\n",
    "# (4) Compute confidence intervals for the above summary statistics by classical, bootstrap, and Bayesian methods; and\n",
    "\n",
    "# (5) Leverage confidence intervals in performing hypothesis tests to determine if the differences in pairs and multiple populations are significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "    \n",
    "    For the final three sections I will split the work by two areas: Bayesian, Bootstrap vs Classical. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Basic Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary Statistics\n",
    "\n",
    "print(auto_new.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "\n",
    "    The likelihood is the probability seeing our data x given the parameter θ this is written as p(X|θ). The likelihood distribution allows is to specify how we think the data was generated. In this case we know how the data was generated and we can think of it as being generated from a Bernoulli Distribution.\n",
    "    \n",
    "    In this distrbution there is a parameter p which is the proability of getting a 1 and the probability of getting a 0 is 1-p. For price that is the probability the price of a car is >11,374 which based off the mean of the new dataset that probability is .34 and probability of not having car with a price above the mean is .66. For horsepower that is the probability of the horsepower of a car > 171 which based off the mean of the new dataset that probility is .01 and the probability of not having a car with horsepower >171 is .99. For height that is the probability that the height of a car >54 which based off the mean of the new dataset that probability is .53 and probability of not having a car with height >54 is .47."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Likehood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price\n",
    "\n",
    "#Computing Likelihood\n",
    "price = auto_new.loc[:,'price']\n",
    "likelihood = np.product(st.bernoulli.pmf(price,.3375))\n",
    "print(\"This is the likelihood of price:\", likelihood)\n",
    "\n",
    "#Graphing Likelihood\n",
    "sns.set(style='ticks', palette='Set2')\n",
    "params = np.linspace(0, 1, 100)\n",
    "p_x = [np.product(st.bernoulli.pmf(price, p)) for p in params]\n",
    "plt.plot(params, p_x)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "\n",
    "    This graph shows the distribution of the likelihood for price with a sample of 100. As you can see the peak is around .34."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horespower\n",
    "\n",
    "#Computing Likelihood\n",
    "hp = auto_new.loc[:,'horsepower']\n",
    "likelihood = np.product(st.bernoulli.pmf(price,.3375))\n",
    "print(\"This is the likelihood of horsepower:\", likelihood)\n",
    "\n",
    "#Graphing Likelihood\n",
    "sns.set(style='ticks', palette='Set2')\n",
    "params = np.linspace(0, 1, 100)\n",
    "p_x = [np.product(st.bernoulli.pmf(hp, p)) for p in params]\n",
    "plt.plot(params, p_x)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "    \n",
    "        This graph shows the distribution of the likelihood for horsepower with a sample of 100. As you can see the peak is around 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Height\n",
    "\n",
    "#Computing Likelihood\n",
    "height = auto_new.loc[:,'height']\n",
    "likelihood = np.product(st.bernoulli.pmf(price,.3375))\n",
    "print(\"This is the likelihood of height:\", likelihood)\n",
    "\n",
    "#Graphing Likelihood\n",
    "sns.set(style='ticks', palette='Set2')\n",
    "params = np.linspace(0, 1, 100)\n",
    "p_x = [np.product(st.bernoulli.pmf(height, p)) for p in params]\n",
    "plt.plot(params, p_x)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "\n",
    "    This graph shows the distribution of the likelihood for price with a sample of 100. As you can see the peak is around .53."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price\n",
    "\n",
    "p_fair = np.array([np.product(st.bernoulli.pmf(price, p)) for p in params])\n",
    "p_fair = p_fair / np.sum(p_fair)\n",
    "plt.plot(params, p_fair)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "      In this case the prior distribution for price is exremely similar to the likelihood distributio for price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horsepower\n",
    "\n",
    "p_fair = np.array([np.product(st.bernoulli.pmf(hp, p)) for p in params])\n",
    "p_fair = p_fair / np.sum(p_fair)\n",
    "plt.plot(params, p_fair)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "      In this case the prior distribution for horsepower is exremely similar to the likelihood distributio for horsepower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Height\n",
    "\n",
    "p_fair = np.array([np.product(st.bernoulli.pmf(height, p)) for p in params])\n",
    "p_fair = p_fair / np.sum(p_fair)\n",
    "plt.plot(params, p_fair)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "    In this case the prior distribution for height is exremely similar to the likelihood distributio for height."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Price\n",
    "\n",
    "sns.set(style='ticks', palette='Set2')\n",
    "params = np.linspace(0, 1, 100)\n",
    "likelihood = [np.product(st.bernoulli.pmf(price, p)) for p in params]\n",
    "p_fair = np.array([np.product(st.bernoulli.pmf(price, p)) for p in params])\n",
    "prior = p_fair / np.sum(p_fair)\n",
    "posterior = [prior[i] * likelihood[i] for i in range(prior.shape[0])]\n",
    "posterior = posterior / np.sum(posterior)\n",
    "fig, axes = plt.subplots(3, 1, sharex=True, figsize=(8,8))\n",
    "axes[0].plot(params, likelihood)\n",
    "axes[0].set_title(\"Price Sampling Distribution\")\n",
    "axes[1].plot(params, prior)\n",
    "axes[1].set_title(\"Price Prior Distribution\")\n",
    "axes[2].plot(params, posterior)\n",
    "axes[2].set_title(\"Price Posterior Distribution\")\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Horsepower\n",
    "\n",
    "sns.set(style='ticks', palette='Set2')\n",
    "params = np.linspace(0, 1, 100)\n",
    "likelihood = [np.product(st.bernoulli.pmf(hp, p)) for p in params]\n",
    "p_fair = np.array([np.product(st.bernoulli.pmf(hp, p)) for p in params])\n",
    "prior = p_fair / np.sum(p_fair)\n",
    "posterior = [prior[i] * likelihood[i] for i in range(prior.shape[0])]\n",
    "posterior = posterior / np.sum(posterior)\n",
    "fig, axes = plt.subplots(3, 1, sharex=True, figsize=(8,8))\n",
    "axes[0].plot(params, likelihood)\n",
    "axes[0].set_title(\"Horsepower Sampling Distribution\")\n",
    "axes[1].plot(params, prior)\n",
    "axes[1].set_title(\"Horsepower Prior Distribution\")\n",
    "axes[2].plot(params, posterior)\n",
    "axes[2].set_title(\"Horsepower Posterior Distribution\")\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Height\n",
    "\n",
    "sns.set(style='ticks', palette='Set2')\n",
    "params = np.linspace(0, 1, 100)\n",
    "likelihood = [np.product(st.bernoulli.pmf(height, p)) for p in params]\n",
    "p_fair = np.array([np.product(st.bernoulli.pmf(height, p)) for p in params])\n",
    "prior = p_fair / np.sum(p_fair)\n",
    "posterior = [prior[i] * likelihood[i] for i in range(prior.shape[0])]\n",
    "posterior = posterior / np.sum(posterior)\n",
    "fig, axes = plt.subplots(3, 1, sharex=True, figsize=(8,8))\n",
    "axes[0].plot(params, likelihood)\n",
    "axes[0].set_title(\"Height Sampling Distribution\")\n",
    "axes[1].plot(params, prior)\n",
    "axes[1].set_title(\"Height Prior Distribution\")\n",
    "axes[2].plot(params, posterior)\n",
    "axes[2].set_title(\"Height Posterior Distribution\")\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "    For each of the features: Price, Height, and Horsepower, they all had very similar likelihood, prior, and posterior distributions. In this case the Baynesian model does not give us many advantages as our own specification of the sampling distribution turned out to be very close to actual distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap vs Classical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Bootstrap Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bootstrap\n",
    "\n",
    "Auto_bootstrap = Auto.sample(frac=1, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "    \n",
    "     Bootstrapping is continued resampling with equivalent size and replacement from an original dataset. It allows us to make the sample size larger without generating more results. In the next section I will be comparing a bootstrap dataset with the original sample.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset\n",
    "\n",
    "print('Dataset Summary Statistics:',Auto.describe())\n",
    "\n",
    "#Bootstrap Sample\n",
    "\n",
    "print('Bootstrap Summary Statistics:',Auto_bootstrap.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms\n",
    "\n",
    "# Price - dataset\n",
    "dataset_hist = plot_hist(Auto.loc[:,'price'])\n",
    "print('Dataset Price Histogram')\n",
    "plt.show(dataset_hist)\n",
    "\n",
    "# Price - bootstrap\n",
    "bootstrap_hist = plot_hist(Auto_bootstrap.loc[:,'price'])\n",
    "print('Boostrap Price Histogram')\n",
    "plt.show(bootstrap_hist)\n",
    "\n",
    "# Horsepower - dataset\n",
    "dataset_hist = plot_hist(Auto.loc[:,'horsepower'])\n",
    "print('Dataset Price Histogram')\n",
    "plt.show(dataset_hist)\n",
    "\n",
    "# Horsepower - bootstrap\n",
    "bootstrap_hist = plot_hist(Auto_bootstrap.loc[:,'horsepower'])\n",
    "print('Boostrap Price Histogram')\n",
    "plt.show(bootstrap_hist)\n",
    "\n",
    "# Height - dataset\n",
    "dataset_hist = plot_hist(Auto.loc[:,'height'])\n",
    "print('Dataset Price Histogram')\n",
    "plt.show(dataset_hist)\n",
    "\n",
    "# Height - bootstrap\n",
    "bootstrap_hist = plot_hist(Auto_bootstrap.loc[:,'height'])\n",
    "print('Boostrap Price Histogram')\n",
    "plt.show(bootstrap_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments: \n",
    "\n",
    "    The bootstrap sample appears to be very similar to the dataset however they are still slightly different. The distribution across all three variables is very similar as are the mean values. However, for price the Q3 value is significantly different in the bootstrap sample then in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments: \n",
    "\n",
    "    I will create confidence intervals for both the bootstrap sample and the dataset using a 95% confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Price - Dataset\n",
    "\n",
    "price_ci = mean_confidence_interval(Auto.loc[:,\"price\"], confidence=0.95)\n",
    "print(price_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Price - Bootstrap\n",
    "\n",
    "price_ci_bs = mean_confidence_interval(Auto_bootstrap.loc[:,\"price\"], confidence=0.95)\n",
    "print(price_ci_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Horsepower - Dataset\n",
    "\n",
    "hp_ci = mean_confidence_interval(Auto.loc[:,\"horsepower\"], confidence=0.95)\n",
    "print(hp_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Horsepower - Bootstrap\n",
    "\n",
    "hp_ci_bs = mean_confidence_interval(Auto_bootstrap.loc[:,\"horsepower\"], confidence=0.95)\n",
    "print(hp_ci_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Height - Dataset\n",
    "\n",
    "height_ci = mean_confidence_interval(Auto.loc[:,\"height\"], confidence=0.95)\n",
    "print(height_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Height - Bootstrap\n",
    "\n",
    "height_ci_bs = mean_confidence_interval(Auto_bootstrap.loc[:,\"height\"], confidence=0.95)\n",
    "print(height_ci_bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "\n",
    "    A confidence interval can be interpretted as if we repeated this process many many times then about 95% of the invervals captured will capture the true mean. In this case, most of the variables have very simimlar confidence intervals except for price. The dataset and bootstrap sample have largely different bounds. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "    \n",
    "    Because of the differences between the bootstrap of price and the dataset of price, I want to examine this further and see if there are siginficant differences between the two population means. To do this I will plot a series of differences between the sample and bootstrap sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap Difference in Means\n",
    "\n",
    "# price\n",
    "diffs = []\n",
    "price = Auto.loc[:,\"price\"]\n",
    "price_bs = Auto_bootstrap.loc[:,\"price\"]\n",
    "for i in range(1000):\n",
    "    sample = price.sample(frac = 1.0, replace = True)\n",
    "    price_mean = price.mean()\n",
    "    bs_mean = sample.mean()\n",
    "    diffs.append(price_mean - bs_mean)\n",
    "diffs = pd.Series(diffs)\n",
    "\n",
    "plot_hist(diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "    \n",
    "    The graph above plots the difference of means between the dataset and a repeated bootstrap sample of price. Based off this graph it appears that there is no significant difference in means between the dataset and repeated bootstramp samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap Difference in Means\n",
    "\n",
    "# horsepower\n",
    "diffs = []\n",
    "horsepower = Auto.loc[:,\"horsepower\"]\n",
    "horsepower_bs = Auto_bootstrap.loc[:,\"horsepower\"]\n",
    "for i in range(1000):\n",
    "    sample = horsepower.sample(frac = 1.0, replace = True)\n",
    "    hp_mean = horsepower.mean()\n",
    "    bs_mean = sample.mean()\n",
    "    diffs.append(hp_mean - bs_mean)\n",
    "diffs = pd.Series(diffs)\n",
    "\n",
    "plot_hist(diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "\n",
    "    Based off this graph it appears that there is no significant difference in means between the dataset and repeated bootstramp samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap Difference in Means\n",
    "\n",
    "# height\n",
    "diffs = []\n",
    "height = Auto.loc[:,\"height\"]\n",
    "height_bs = Auto_bootstrap.loc[:,\"height\"]\n",
    "for i in range(1000):\n",
    "    sample = height.sample(frac = 1.0, replace = True)\n",
    "    height_mean = height.mean()\n",
    "    bs_mean = sample.mean()\n",
    "    diffs.append(height_mean - bs_mean)\n",
    "diffs = pd.Series(diffs)\n",
    "\n",
    "plot_hist(diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "\n",
    "    Based off this graph it appears that there is no significant difference in means between the dataset and repeated bootstramp samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T - Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "    \n",
    "    I will now be running a t-test between each of the dataset means against their bootstrap means to see if there is any significant difference between the two means. If the pvalue is less than .05 than that means we can reject the null hypothesis that the two means are equal. If the pvalue is greater than .05 than we fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-test\n",
    "\n",
    "#price\n",
    "price = Auto.loc[:,\"price\"]\n",
    "price_bs = Auto_bootstrap.loc[:,\"price\"]\n",
    "test = t_test(price, price_bs, 0.05)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "\n",
    "    With a pvalue of 0.7 we fail to reject the null hypothesis that the mean for price from the dataset and mean for price from the bootstrap sample are equalivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-test\n",
    "\n",
    "#horsepower\n",
    "hp = Auto.loc[:,\"horsepower\"]\n",
    "hp_bs = Auto_bootstrap.loc[:,\"horsepower\"]\n",
    "test = t_test(hp, hp_bs, 0.05)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "\n",
    "    With a pvalue of 0.92 we fail to reject the null hypothesis that the mean for horsepower from the dataset and mean for horsepower from the bootstrap sample are equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-test\n",
    "\n",
    "#height\n",
    "height = Auto.loc[:,\"height\"]\n",
    "height_bs = Auto_bootstrap.loc[:,\"height\"]\n",
    "test = t_test(height, height_bs, 0.05)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "\n",
    "    With a pvalue of 0.77 we fail to reject the null hypothesis that the mean for height from the dataset and mean for height from the bootstrap sample are equivalent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
