{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 09 Assignment\n",
    "\n",
    "## Author - Matthew Denko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "    (1) Leverage Naïve Bayes algorithm to classify build a model using the data from previous milestones.\n",
    "    \n",
    "    (2) Briefly summarize your findings on using Naïve Bayes.\n",
    "    \n",
    "    (3) Is Naïve Bayes more accurate than the regression model you used in Milestone 3?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Leverage Naïve Bayes algorithm to classify build a model using the data from previous milestones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Citation\n",
    "\n",
    "source_citation = \"Dua, D. and Karra Taniskidou, E. (2017). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\"\n",
    "print(\"source citation = \",source_citation)\n",
    "url = 'https://archive.ics.uci.edu/ml/datasets/Adult'\n",
    "print(\"url =\",url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import *\n",
    "import matplotlib\n",
    "import statsmodels.api as sms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading url\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "Adult= pd.read_csv(url, header=None)\n",
    "\n",
    "# Assigning reasonable column names\n",
    "\n",
    "Adult.columns = [\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\n",
    "                 \"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\">50K, <=50k\"]\n",
    "print(Adult.columns)\n",
    "Adult.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing cases with missing data\n",
    "\n",
    "Adult = Adult.replace(to_replace= \"?\", value=float(\"NaN\"))\n",
    "Adult_null = Adult.isnull().sum()\n",
    "print(Adult_null)\n",
    "print(\"There are 0 columns with missing data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Distribution of Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age\n",
    "\n",
    "age_hist = plt.hist(Adult.loc[:,'age'])\n",
    "plt.title(\"Age Histogram\")\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('frequency')\n",
    "plt.show(age_hist)\n",
    "age_comment = \"\"\"Age is strongly skewed right and does not represent a \n",
    "normal distribution, there is a higher concentrate of younger participants to \n",
    "older.\"\"\"\n",
    "print(age_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#education-num\n",
    "\n",
    "education_num_hist = plt.hist(Adult.loc[:,'education-num'])\n",
    "plt.title(\"Education Num Histogram\")\n",
    "plt.xlabel('education-num')\n",
    "plt.ylabel('frequency')\n",
    "plt.show(education_num_hist)\n",
    "education_num_comment = \"\"\"education num has a somewhat bi-modal distribution\n",
    "with one center around 8-12 and another at 14\"\"\"\n",
    "print(education_num_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#capital-gain\n",
    "\n",
    "capital_gain_hist = plt.hist(Adult.loc[:,'capital-gain'])\n",
    "plt.title(\"Capital Gain Histogram\")\n",
    "plt.xlabel('capital-gain')\n",
    "plt.ylabel('frequency')\n",
    "plt.show(capital_gain_hist)\n",
    "capital_gain_comment = \"\"\"capital gain is a single modal distribution that\n",
    "appears slightly right skewed\"\"\"\n",
    "print(capital_gain_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hours-per-week\n",
    "\n",
    "hours_per_week_hist = plt.hist(Adult.loc[:,'hours-per-week'])\n",
    "plt.title(\"Hours-Per-Week Histogram\")\n",
    "plt.xlabel('hours-per-week')\n",
    "plt.ylabel('frequency')\n",
    "plt.show(hours_per_week_hist)\n",
    "hours_per_week_comment = \"\"\"hours per week appears to be close to a normal\n",
    "distribution, with some slight right skewness\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rename columns\n",
    "\n",
    "Adult.loc[:,\"capitalgain\"] = Adult.loc[:,\"capital-gain\"]\n",
    "Adult.loc[:,\"educationnum\"] = Adult.loc[:,\"education-num\"]\n",
    "Adult = Adult.drop(\"capital-gain\",axis = 1)\n",
    "Adult = Adult.drop(\"education-num\", axis = 1)\n",
    "\n",
    "# Define the target and features:\n",
    "\n",
    "target_label = 'capitalgain'\n",
    "non_features = [\"workclass\",\"fnlwgt\",\"education\",\"marital-status\",\"occupation\",\n",
    "                 \"relationship\",\"race\",\"sex\",\"capital-loss\",\"native-country\",\">50K, <=50k\"]\n",
    "feature_labels = [x for x in Adult.columns if x not in [target_label] + non_features]\n",
    "\n",
    "# Filter out non-features and non-targets\n",
    "\n",
    "Adult = Adult.drop(non_features, axis=1)\n",
    "\n",
    "# One-hot encode inputs\n",
    "\n",
    "Adult_expanded = pd.get_dummies(Adult, drop_first=True)\n",
    "print('DataFrame one-hot-expanded shape: {}'.format(Adult_expanded.shape))\n",
    "\n",
    "# Get target and original x-matrix\n",
    "\n",
    "y = Adult[target_label]\n",
    "x = Adult.as_matrix(columns=feature_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, \n",
    "                                  test_size=0.3,random_state=42) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# train the model on the training sets only\n",
    "\n",
    "gnb_model = gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"R2 score:\",metrics.r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Briefly summarize your findings on using Naïve Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "\n",
    "        Naive Bayes  makes the assumption that the effect of each feature in the dataset is independent of other features instead of directly counting each probability. This adjusts the model so that each feature of the dataset is independent of other features. The accuarcy for this model was high (~71%) howver the rscored value was extremly low meaning that this model does not do a good job of explaining the variance in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Is Naïve Bayes more accurate than the regression model you used in Milestone 3?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "\n",
    "    The accuarcy score and R2 score of the Naive Bayes model is lower than the accuracy score and R2 score of the Regression model. This indicates that the features are better predictors when they are not assumed to be indpendent of all other features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
